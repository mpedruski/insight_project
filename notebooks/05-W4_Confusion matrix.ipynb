{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score: 0.3740837933218713\n",
      "Confusion matrix: [[3346 1150  845 ...    0    0    0]\n",
      " [1730 1491 1948 ...    0    0    0]\n",
      " [ 720 1194 3213 ...    0    0    0]\n",
      " ...\n",
      " [   0    0    0 ...    0    0    0]\n",
      " [   0    0    0 ...    0    0    0]\n",
      " [   0    0    0 ...    0    0    0]]\n",
      "Full classification report:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.55      0.62      0.59      5355\n",
      "         1.0       0.33      0.28      0.31      5241\n",
      "         2.0       0.31      0.60      0.41      5343\n",
      "         3.0       0.19      0.05      0.08      2274\n",
      "         4.0       0.19      0.04      0.06      1208\n",
      "         5.0       0.17      0.02      0.04       699\n",
      "         6.0       0.13      0.02      0.04       449\n",
      "         7.0       0.18      0.03      0.05       326\n",
      "         8.0       0.13      0.02      0.04       215\n",
      "         9.0       0.33      0.02      0.04       166\n",
      "        10.0       0.09      0.01      0.02       153\n",
      "        11.0       0.09      0.02      0.03       115\n",
      "        12.0       0.07      0.01      0.02        86\n",
      "        13.0       0.14      0.02      0.03        54\n",
      "        14.0       0.05      0.03      0.03        39\n",
      "        15.0       0.00      0.00      0.00        35\n",
      "        16.0       0.00      0.00      0.00        43\n",
      "        17.0       0.00      0.00      0.00        25\n",
      "        18.0       0.00      0.00      0.00        21\n",
      "        19.0       0.00      0.00      0.00        20\n",
      "        20.0       0.09      0.06      0.07        16\n",
      "        21.0       0.00      0.00      0.00        13\n",
      "        22.0       0.00      0.00      0.00        22\n",
      "        23.0       0.20      0.06      0.09        17\n",
      "        24.0       0.00      0.00      0.00        14\n",
      "        25.0       0.25      0.08      0.12        13\n",
      "        26.0       0.00      0.00      0.00        11\n",
      "        27.0       1.00      0.06      0.12        16\n",
      "        28.0       0.00      0.00      0.00        10\n",
      "        29.0       0.00      0.00      0.00        12\n",
      "        30.0       0.00      0.00      0.00         4\n",
      "        31.0       0.00      0.00      0.00         4\n",
      "        32.0       0.00      0.00      0.00         5\n",
      "        33.0       0.00      0.00      0.00         5\n",
      "        34.0       0.00      0.00      0.00         2\n",
      "        35.0       0.00      0.00      0.00         5\n",
      "        36.0       0.00      0.00      0.00         5\n",
      "        37.0       0.00      0.00      0.00         3\n",
      "        38.0       0.00      0.00      0.00         2\n",
      "        39.0       0.00      0.00      0.00         1\n",
      "        40.0       0.00      0.00      0.00         1\n",
      "        41.0       0.00      0.00      0.00         4\n",
      "        42.0       0.00      0.00      0.00         2\n",
      "        43.0       0.00      0.00      0.00         1\n",
      "        44.0       0.00      0.00      0.00         3\n",
      "        45.0       0.00      0.00      0.00         2\n",
      "        46.0       0.00      0.00      0.00         3\n",
      "        47.0       0.00      0.00      0.00         2\n",
      "        48.0       0.00      0.00      0.00         2\n",
      "        49.0       0.00      0.00      0.00         3\n",
      "        50.0       0.00      0.00      0.00         2\n",
      "        52.0       0.00      0.00      0.00         1\n",
      "        53.0       0.00      0.00      0.00         1\n",
      "        54.0       0.00      0.00      0.00         1\n",
      "        56.0       0.00      0.00      0.00         1\n",
      "        57.0       0.00      0.00      0.00         2\n",
      "        58.0       0.00      0.00      0.00         1\n",
      "        59.0       0.00      0.00      0.00         1\n",
      "        60.0       0.00      0.00      0.00         1\n",
      "        61.0       0.00      0.00      0.00         1\n",
      "        63.0       0.00      0.00      0.00         1\n",
      "        64.0       0.00      0.00      0.00         2\n",
      "        67.0       0.00      0.00      0.00         1\n",
      "        68.0       0.00      0.00      0.00         1\n",
      "        69.0       0.00      0.00      0.00         0\n",
      "        70.0       0.00      0.00      0.00         3\n",
      "        72.0       0.00      0.00      0.00         1\n",
      "        75.0       0.00      0.00      0.00         0\n",
      "        76.0       0.00      0.00      0.00         1\n",
      "        77.0       0.00      0.00      0.00         2\n",
      "        78.0       0.00      0.00      0.00         3\n",
      "        79.0       0.00      0.00      0.00         1\n",
      "        83.0       0.00      0.00      0.00         2\n",
      "        87.0       0.00      0.00      0.00         1\n",
      "        92.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.37     22102\n",
      "   macro avg       0.06      0.03      0.03     22102\n",
      "weighted avg       0.34      0.37      0.33     22102\n",
      "\n",
      "Accuracy of predctions in the neighbourhood: 0.7372635960546556\n",
      "Feature importance for forest model: [0.42751728 0.20336019 0.0515251  0.16722284 0.10967662 0.04069797]\n",
      "[3346 1150  845   12    2]\n",
      "[1730 1491 1948   54    6]\n",
      "[ 720 1194 3213  159   28]\n",
      "[ 141  343 1616  116   38]\n",
      "[ 44 130 881  85  47]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mpedruski/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mpedruski/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy if the model was predicting at random based on available ratios: 0.18649895937019273\n",
      "Full classification report for random data:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.24      0.24      0.24      5355\n",
      "         1.0       0.24      0.24      0.24      5241\n",
      "         2.0       0.24      0.23      0.23      5343\n",
      "         3.0       0.10      0.10      0.10      2274\n",
      "         4.0       0.05      0.05      0.05      1208\n",
      "         5.0       0.03      0.03      0.03       699\n",
      "         6.0       0.02      0.02      0.02       449\n",
      "         7.0       0.02      0.02      0.02       326\n",
      "         8.0       0.00      0.00      0.00       215\n",
      "         9.0       0.01      0.01      0.01       166\n",
      "        10.0       0.02      0.02      0.02       153\n",
      "        11.0       0.00      0.00      0.00       115\n",
      "        12.0       0.00      0.00      0.00        86\n",
      "        13.0       0.00      0.00      0.00        54\n",
      "        14.0       0.00      0.00      0.00        39\n",
      "        15.0       0.00      0.00      0.00        35\n",
      "        16.0       0.00      0.00      0.00        43\n",
      "        17.0       0.00      0.00      0.00        25\n",
      "        18.0       0.00      0.00      0.00        21\n",
      "        19.0       0.00      0.00      0.00        20\n",
      "        20.0       0.00      0.00      0.00        16\n",
      "        21.0       0.00      0.00      0.00        13\n",
      "        22.0       0.00      0.00      0.00        22\n",
      "        23.0       0.00      0.00      0.00        17\n",
      "        24.0       0.00      0.00      0.00        14\n",
      "        25.0       0.00      0.00      0.00        13\n",
      "        26.0       0.00      0.00      0.00        11\n",
      "        27.0       0.00      0.00      0.00        16\n",
      "        28.0       0.00      0.00      0.00        10\n",
      "        29.0       0.00      0.00      0.00        12\n",
      "        30.0       0.00      0.00      0.00         4\n",
      "        31.0       0.00      0.00      0.00         4\n",
      "        32.0       0.00      0.00      0.00         5\n",
      "        33.0       0.00      0.00      0.00         5\n",
      "        34.0       0.00      0.00      0.00         2\n",
      "        35.0       0.00      0.00      0.00         5\n",
      "        36.0       0.00      0.00      0.00         5\n",
      "        37.0       0.00      0.00      0.00         3\n",
      "        38.0       0.00      0.00      0.00         2\n",
      "        39.0       0.00      0.00      0.00         1\n",
      "        40.0       0.00      0.00      0.00         1\n",
      "        41.0       0.00      0.00      0.00         4\n",
      "        42.0       0.00      0.00      0.00         2\n",
      "        43.0       0.00      0.00      0.00         1\n",
      "        44.0       0.00      0.00      0.00         3\n",
      "        45.0       0.00      0.00      0.00         2\n",
      "        46.0       0.00      0.00      0.00         3\n",
      "        47.0       0.00      0.00      0.00         2\n",
      "        48.0       0.00      0.00      0.00         2\n",
      "        49.0       0.00      0.00      0.00         3\n",
      "        50.0       0.00      0.00      0.00         2\n",
      "        52.0       0.00      0.00      0.00         1\n",
      "        53.0       0.00      0.00      0.00         1\n",
      "        54.0       0.00      0.00      0.00         1\n",
      "        56.0       0.00      0.00      0.00         1\n",
      "        57.0       0.00      0.00      0.00         2\n",
      "        58.0       0.00      0.00      0.00         1\n",
      "        59.0       0.00      0.00      0.00         1\n",
      "        60.0       0.00      0.00      0.00         1\n",
      "        61.0       0.00      0.00      0.00         1\n",
      "        63.0       0.00      0.00      0.00         1\n",
      "        64.0       0.00      0.00      0.00         2\n",
      "        67.0       0.00      0.00      0.00         1\n",
      "        68.0       0.00      0.00      0.00         1\n",
      "        70.0       0.00      0.00      0.00         3\n",
      "        72.0       0.00      0.00      0.00         1\n",
      "        76.0       0.00      0.00      0.00         1\n",
      "        77.0       0.00      0.00      0.00         2\n",
      "        78.0       0.00      0.00      0.00         3\n",
      "        79.0       0.00      0.00      0.00         1\n",
      "        83.0       0.00      0.00      0.00         2\n",
      "        87.0       0.00      0.00      0.00         1\n",
      "        92.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.19     22102\n",
      "   macro avg       0.01      0.01      0.01     22102\n",
      "weighted avg       0.19      0.19      0.19     22102\n",
      "\n",
      "Accuracy if the model was predicting at random (expanded ): 0.48574789611799835\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import confusion_matrix, classification_report, plot_confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from joblib import dump, load\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def major_classes_undersampler(data, variable, class_to_match):\n",
    "    '''(DataFrame, str, int) -> DataFrame\n",
    "    Accepts a dataframe as an argument, and a variable name that will be used\n",
    "    to reduce the size of the dataframe by undersampling majority class data'''\n",
    "    minority_class_len = len(data[data[variable]==class_to_match])\n",
    "    logging.debug(\"Demand classes: {}\".format(data.groupby(variable)[variable].count()))\n",
    "    ### classes_to_undersample should be used with caution, it assumes that indices\n",
    "    ### map directly to demand categories, which is true for my data, but my not be for all\n",
    "    classes_to_undersample = np.where(data.groupby(variable)[variable].count()>minority_class_len)[0]\n",
    "    logging.debug(\"Classes to undersample: {}\".format(classes_to_undersample))\n",
    "    indices_to_keep = []\n",
    "    for i in classes_to_undersample:\n",
    "        indices_to_keep.append(np.random.choice(data[data['Demand']==i].index.tolist(),\n",
    "            minority_class_len, replace = False))\n",
    "    minority_class_indices = data[data['Demand']>=class_to_match].index\n",
    "    under_sample_indices = np.concatenate([minority_class_indices,indices_to_keep[0],indices_to_keep[1]])\n",
    "    logging.debug(\"indices to keep: {}\".format(under_sample_indices))\n",
    "    return data.loc[under_sample_indices]\n",
    "\n",
    "def train_model(data, y_var, x_vars):\n",
    "    ''' (dataframe, str, [str]) -> model\n",
    "    Returns a fitted random forest model from an input dataframe'''\n",
    "    y = data[y_var]\n",
    "    x = data[x_vars]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "    regr = RandomForestClassifier(max_depth=16, min_samples_leaf=8, bootstrap = False)\n",
    "    regr_model = regr.fit(x_train, y_train)\n",
    "    return regr_model, x_test, y_test\n",
    "\n",
    "def model_accuracy(regr, x_test, y_test):\n",
    "    '''(model, array, array) -> None\n",
    "    Takes in a fitted classification model and prints output reports directly\n",
    "    to the terminal.\n",
    "    '''\n",
    "    y_pred = regr.predict(x_test)\n",
    "    print(\"Model score: {}\".format(regr_1.score(x_test,y_test)))\n",
    "    conf_mat = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion matrix: {}\".format(conf_mat))\n",
    "    s = []\n",
    "    for i in range(len(conf_mat)):\n",
    "        if i == 0:\n",
    "            s.append(conf_mat[i,i]+conf_mat[i,i+1])\n",
    "        elif i == conf_mat.shape[0]-1:\n",
    "            s.append(conf_mat[i,i]+conf_mat[i, i-1])\n",
    "        else:\n",
    "            s.append(conf_mat[i,i]+conf_mat[i,i-1]+conf_mat[i,i+1])\n",
    "    total_sum = sum(sum(conf_mat))\n",
    "    print('Full classification report: {}'.format(classification_report(y_test,y_pred)))\n",
    "    ### Straight up precision just says how many items were exactly right\n",
    "    ### Confusion matrix shows many items are misclassified as closely related values\n",
    "    ### (i.e. 4 as 3 or 5, which is an acceptable margin of error for my problem).\n",
    "    print('Accuracy of predctions in the neighbourhood: {}'.format(sum(s)/total_sum))\n",
    "    print('Feature importance for forest model: {}'.format(regr_1.feature_importances_))\n",
    "    for i in conf_mat[0:5]:\n",
    "        print(i[0:5])\n",
    "\n",
    "def random_accuracy(regr,y_test):\n",
    "    '''(model, array, array) -> None\n",
    "    Takes in a fitted classification model and prints output accuracy reports for\n",
    "    random selection of y_test items.\n",
    "    '''\n",
    "    total_sum = len(y_test)\n",
    "    random_prob_test_array = []\n",
    "    for i in y_test:\n",
    "        random_prob_test_array.append(np.random.choice(y_test))\n",
    "    random_prob_test_array = np.array(random_prob_test_array)\n",
    "    count = len(np.where(random_prob_test_array==y_test)[0])\n",
    "    print('Accuracy if the model was predicting at random based on available ratios: {}'.format(count/total_sum))\n",
    "    print('Full classification report for random data: {}'.format(classification_report(y_test,random_prob_test_array)))\n",
    "    expanded_count = []\n",
    "    true_vals = np.array(y_test)\n",
    "    for i in range(random_prob_test_array.shape[0]):\n",
    "        if true_vals[i] == random_prob_test_array[i]:\n",
    "            expanded_count.append(random_prob_test_array[i])\n",
    "        elif true_vals[i] == random_prob_test_array[i] + 1:\n",
    "            expanded_count.append(random_prob_test_array[i])\n",
    "        elif true_vals[i] == random_prob_test_array[i] + -1:\n",
    "            expanded_count.append(random_prob_test_array[i])\n",
    "    print('Accuracy if the model was predicting at random (expanded ): {}'.format(len(expanded_count)/total_sum))\n",
    "\n",
    "### Classification of demand based on historical data\n",
    "logging.basicConfig(level=logging.CRITICAL,format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "np.random.seed(31415)\n",
    "\n",
    "### Determine paths to datasets and load into pandas dataframe\n",
    "processed_folder = Path(\"../data/processed\")\n",
    "file_to_open = processed_folder / 'feature_labels_for_each_title.csv'\n",
    "model_parameters = processed_folder / 'decision_tree_parameters.joblib'\n",
    "\n",
    "### Loading response dataset\n",
    "df = pd.read_csv(file_to_open)\n",
    "df = major_classes_undersampler(df,'Demand',2)\n",
    "### Training model\n",
    "predictor_variables = ['Auteur_labels', 'Editeur_labels', 'Pays_labels',\n",
    "       'Years_offset', 'Document_type_labels', 'Language_type_labels']\n",
    "regr_1, x_test, y_test = train_model(df,'Demand',predictor_variables)\n",
    "\n",
    "### Assess model accuracy\n",
    "model_accuracy(regr_1,x_test, y_test)\n",
    "### Confirm that the model is doing better than random\n",
    "random_accuracy(regr_1,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
